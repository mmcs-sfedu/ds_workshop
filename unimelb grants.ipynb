{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных и логистическая регрессия для задачи бинарной классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегодня мы познакомимся с основными техниками предобработки данных, а так же применим их для обучения модели логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассматривается [задача](https://www.kaggle.com/c/unimelb#description) с сайта Kaggle.com: по 252 признака, связанных с заявкой на грант (область исследований учёных, информация по их академическому бэкграунду, размер гранта, область, в которой он выдаётся) предсказать, будет ли заявка принята. Датасет включает в себя информацию по 8708 заявкам на гранты, которые были поданы в университете Мельбурна в период с 2004 по 2008 год.\n",
    "\n",
    "* unimelb_training.csv - тренировочная выборка\n",
    "* unimelb_test.csv - тестовая выборка\n",
    "* unimelb_example.csv - образец ответа, ожидаемого системой\n",
    "\n",
    "Мы рассмотрим урезанную выборку, которую можно получить [здесь](https://yadi.sk/d/zXlTicxG3KxhFL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Загрузите в память имеющиеся данные в переменную $data$ и посмотрите на их размерность с помощью свойства shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.**\n",
    "Выделите из датасета целевую переменную Grant.Status и обозначьте её $y$  \n",
    "Используя функцию drop, удалите из датасета выбранную целевую переменную и обозначьте оставшийся датасет за $X$  \n",
    "Почему нельзя оставить целевую переменную в составе датасета?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь X отвечает за обучающую выборку, y - за ответы на ней"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория по логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После осознания того, какую именно задачу требуется решить на этих данных, следующим шагом при реальном анализе был бы подбор подходящего метода.\n",
    "\n",
    "Логистическая регрессия предсказывает вероятности принадлежности объекта к каждому классу. Сумма ответов логистической регрессии на одном объекте для всех классов равна единице.\n",
    "\n",
    "$$ \\sum_{k=1}^K \\pi_{ik} = 1, \\quad \\pi_k \\equiv P\\,(y_i = k \\mid x_i, \\theta), $$\n",
    "\n",
    "где:\n",
    "- $\\pi_{ik}$ - вероятность принадлежности объекта $x_i$ из выборки $X$ к классу $k$\n",
    "- $\\theta$ - внутренние параметры алгоритма, которые настраиваются в процессе обучения, в случае логистической регрессии - $w, b$\n",
    "\n",
    "Из этого свойства модели в случае бинарной классификации требуется вычислить лишь вероятность принадлежности объекта к одному из классов (вторая вычисляется из условия нормировки вероятностей). Эта вероятность вычисляется, используя логистическую функцию:\n",
    "\n",
    "$$ P\\,(y_i = 1 \\mid x_i, \\theta) = \\frac{1}{1 + \\exp(-w^T x_i-b)} $$\n",
    "\n",
    "Параметры $w$ и $b$ находятся, как решения следующих задач оптимизации.\n",
    "\n",
    "Для L2-регуляризации это:\n",
    "\n",
    "$$ Q(X, y, \\theta) = \\frac{1}{2} w^T w + C \\sum_{i=1}^l \\log ( 1 + \\exp(-y_i (w^T x_i + b ) ) ) \\longrightarrow \\min\\limits_{w,b} $$\n",
    "\n",
    "Для L1-регуляризации это:\n",
    "\n",
    "$$ Q(X, y, \\theta) = \\sum_{d=1}^D |w_d| + C \\sum_{i=1}^l \\log ( 1 + \\exp(-y_i (w^T x_i + b ) ) ) \\longrightarrow \\min\\limits_{w,b} $$\n",
    "\n",
    "$C$ - это стандартный гиперпараметр модели, который регулирует то, насколько сильно мы позволяем модели подстраиваться под данные.\n",
    "\n",
    "**Задание.** Подумайте, в чем отличие L2 и L1 регуляризаций и как это отличие влияет на обучение?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На прошлом занятии мы уже занимались предобработкой данных, и сделали для себя следующие выводы:\n",
    "- все $X$ должны быть числовыми данными (в случае наличия среди них категорий, их требуется некоторым способом преобразовать в вещественные числа)\n",
    "- среди $X$ не должно быть пропущенных значений (т.е. все пропущенные значения перед применением модели следует каким-то образом заполнить)\n",
    "\n",
    "Поэтому базовым этапом в предобработке любого датасета для логистической регрессии будет кодирование категориальных признаков, а так же восполнение или интерпретация пропущенных значений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**. Посмотрите на первые строки выборки data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие признаки есть в датасете? Что они могут обозначать?   \n",
    "**Задание (15 мин)**. Проанализируйте таблицу, обсудите, какие признаки являются числовыми и составьте список их названий, обозначьте его переменной numeric_cols. Остальные признаки являются категориальными --- сформируйте из них список categorical_cols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также в нём присутствуют пропущенные значения. Очевидным решением будет исключение всех данных, у которых пропущено хотя бы одно значение.  \n",
    "**Задание.** Используя функцию dropna, исключите все строки, у которых есть хотя бы одно пропущенное значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что тогда мы выбросим почти все данные, и такой метод решения в данном случае не сработает.\n",
    "\n",
    "Пропущенные значения можно так же интерпретировать, для этого существует несколько способов, они различаются для категориальных и вещественных признаков.\n",
    "\n",
    "Для вещественных признаков:\n",
    "- заменить на 0 (данный признак давать вклад в предсказание для данного объекта не будет)\n",
    "- заменить на среднее (каждый пропущенный признак будет давать такой же вклад, как и среднее значение признака на датасете)\n",
    "\n",
    "Для категориальных:\n",
    "- интерпретировать пропущенное значение, как ещё одну категорию (данный способ является самым естественным, так как в случае категорий у нас есть уникальная возможность не потерять информацию о наличии пропущенных значений; обратите внимание, что в случае вещественных признаков данная информация неизбежно теряется)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Шаг 1. Обработка пропущенных значений.\n",
    "1. Заполните пропущенные вещественные значения в X нулями, средними и медианами по столбцам, назовите полученные датафреймы, состоящие только из вещественных признаков, X_real_zeros, X_real_mean и X_real_median соответственно. Для подсчёта средних используйте функции pandas.\n",
    "2. Заполните пропущенные категориальные значения в X строками 'NA', преобразуйте все категориальные признаки в строки и назовите датафрейм, включающий в себя только категориальные признаки, X_cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование категориальных признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В предыдущей ячейке мы разделили наш датасет ещё на две части: в одной присутствуют только вещественные признаки, в другой только категориальные. Это понадобится нам для раздельной последующей обработке этих данных, а так же для сравнения качества работы тех или иных методов.\n",
    "\n",
    "Для использования модели регрессии требуется преобразовать категориальные признаки в вещественные. Рассмотрим основной способ преоборазования категориальных признаков в вещественные: **one-hot encoding** (другие названия: **бинаризация**, **dummy-кодирование**). Его идея заключается в том, что мы преобразуем категориальный признак при помощи бинарного кода: каждой категории ставим в соответствие набор из нулей и единиц.\n",
    "\n",
    "**Пример**. Посмотрим, как данный метод работает на наборе данных состоящем только из категориальных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "\n",
    "# Рассмотрим простой набор данных следующего вида:\n",
    "categorial_data = pd.DataFrame({'sex': ['male', 'female', 'male', 'female'], \n",
    "                                'nationality': ['American', 'European', 'Asian', 'European']})\n",
    "print('Исходные данные:\\n')\n",
    "print(categorial_data)\n",
    "encoder = DV(sparse = False)\n",
    "# Отберем колонки с категориальными признаками\n",
    "encoded_data = encoder.fit_transform(categorial_data.T.to_dict().values())\n",
    "print('\\nЗакодированные данные:\\n')\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, в первые три колонки оказалась закодирована информация о стране, а во вторые две - о поле. При этом для совпадающих элементов выборки строки будут полностью совпадать. Также из примера видно, что кодирование признаков сильно увеличивает их количество, но полностью сохраняет информацию, в том числе о наличии пропущенных значений (их наличие просто становится одним из бинарных признаков в преобразованных данных). \n",
    "\n",
    "Подумайте, почему важно применять одинаковое преобразование как к обучающим, так и тестовым данным? Почему можно применять кодирование категориальных признаков на обучающей выборке?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Примените one-hot encoding к категориальным признакам из исходного датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для построения метрики качества по результату обучения требуется разделить исходный датасет на обучающую и тестовую выборки (X_train_real_zeros и X_test_real_zeros соответственно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# место для вашего кода  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание класса GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы получили первые наборы данных, для которых выполнены оба ограничения логистической регрессии на входные данные. Обучим на них регрессию, используя имеющийся в библиотеке sklearn функционал по подбору гиперпараметров модели\n",
    "    \n",
    "    optimizer = GridSearchCV(estimator, param_grid)\n",
    "\n",
    "где:\n",
    "- estimator - обучающий алгоритм, для которого будет производиться подбор параметров\n",
    "- param_grid - словарь параметров, ключами которого являются строки-названия, которые передаются алгоритму estimator, а значения - набор параметров для перебора\n",
    "\n",
    "Данный класс выполняет кросс-валидацию обучающей выборки для каждого набора параметров и находит те, на которых алгоритм работает лучше всего. Этот метод позволяет настраивать гиперпараметры по обучающей выборке, избегая переобучения. Некоторые параметры вызова данного класса, которые полезно попробовать поменять в целях достижения лучшего качества:\n",
    "- scoring - функционал качества, максимум которого ищется кросс валидацией, по умолчанию используется функция score() класса esimator\n",
    "- n_jobs - позволяет ускорить кросс-валидацию, выполняя её параллельно, число определяет количество одновременно запущенных задач\n",
    "- cv - количество фолдов, на которые разбивается выборка при кросс-валидации\n",
    "\n",
    "После инициализации класса GridSearchCV, процесс подбора параметров запускается следующим методом:\n",
    "\n",
    "    optimizer.fit(X, y)\n",
    "    \n",
    "На выходе для получения предсказаний можно пользоваться функцией\n",
    "\n",
    "    optimizer.predict(X)\n",
    "    \n",
    "Также можно напрямую получить оптимальный класс estimator и оптимальные параметры, так как они является атрибутами класса GridSearchCV:\n",
    "- best\\_estimator\\_ - лучший алгоритм\n",
    "- best\\_params\\_ - лучший набор параметров\n",
    "\n",
    "Класс логистической регрессии выглядит следующим образом:\n",
    "\n",
    "    estimator = LogisticRegression(penalty)\n",
    "   \n",
    "где penalty принимает либо значение 'l2', либо 'l1'. По умолчанию устанавливается значение 'l2', и везде в задании, если об этом не оговорено особо, предполагается использование логистической регрессии с L2-регуляризацией.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2. Сравнение способов заполнения вещественных пропущенных значений.\n",
    "* Составьте три обучающие выборки из вещественных и категориальных признаков: в одной вещественные признаки, где пропущенные значения заполнены нулями, во второй - средними арифметическими, в третьей - медианами. Рекомендуется записывать в выборки сначала вещественные, а потом категориальные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Обучите на них логистическую регрессию, подбирая параметры из заданной сетки param_grid по методу кросс-валидации с числом фолдов cv=3. В качестве оптимизируемой функции используйте заданную по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10]}\n",
    "cv = 3\n",
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Постройте три графика оценок точности +- их стандратного отклонения в зависимости от гиперпараметра и убедитесь, что вы действительно нашли её максимум. Также обратите внимание на большую дисперсию получаемых оценок (уменьшить её можно увеличением числа фолдов cv). Можно использовать функцию plot_scores, определенную ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_scores(optimizer):\n",
    "    scores = [[item[0]['C'], \n",
    "               item[1], \n",
    "               (np.sum((item[2]-item[1])**2)/(item[2].size-1))**0.5] for item in optimizer.grid_scores_]\n",
    "    scores = np.array(scores)\n",
    "    plt.semilogx(scores[:,0], scores[:,1])\n",
    "    plt.fill_between(scores[:,0], scores[:,1]-scores[:,2], \n",
    "                                  scores[:,1]+scores[:,2], alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "# место для вашего кода   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите в интернете, что такое ROC и ROC AUC.\n",
    "\n",
    "* Получите три метрики качества [ROC AUC](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) на тестовой выборке и сравните их между собой. Какой способ заполнения пропущенных вещественных значений работает лучше? В дальнейшем для выполнения задания в качестве вещественных признаков используйте ту выборку, которая даёт лучшее качество на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# место для вашего кода   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно:** вообще говоря, не вполне логично оптимизировать на кросс-валидации заданный по умолчанию в классе логистической регрессии функционал accuracy, а измерять на тесте AUC ROC, но это, как и ограничение размера выборки, сделано для ускорения работы процесса кросс-валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Масштабирование вещественных признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем как-то улучшить качество классификации. Для этого визуализируем признаки парами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "data_numeric = pd.DataFrame(X_real_zeros, columns=numeric_cols)\n",
    "list_cols = ['Number.of.Successful.Grant.1', 'Year.of.Birth.1']\n",
    "scatter_matrix(data_numeric[list_cols], alpha=0.5, figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из графиков, разные признаки очень сильно отличаются друг от друга по модулю значений (обратите внимание на диапазоны значений осей x и y). В случае обычной регрессии это никак не влияет на качество обучаемой модели, т.к. у меньших по модулю признаков будут большие веса, но при использовании регуляризации, которая штрафует модель за большие веса, регрессия, как правило, начинает работать хуже.\n",
    "\n",
    "В таких случаях всегда рекомендуется делать стандартизацию (масштабирование) признаков, для того чтобы они меньше отличались друг друга по модулю, но при этом не нарушались никакие другие свойства признакового пространства. При этом даже если итоговое качество модели на тесте уменьшается, это повышает её интерпретабельность, потому что новые веса имеют смысл \"значимости\" данного признака для итоговой классификации.\n",
    "\n",
    "Стандартизация осуществляется посредством вычета из каждого признака среднего значения и нормировки на выборочное стандартное отклонение:\n",
    "\n",
    "$$ x^{scaled}_{id} = \\dfrac{x_{id} - \\mu_d}{\\sigma_d}, \\quad \\mu_d = \\frac{1}{N} \\sum_{i=1}^l x_{id}, \\quad \\sigma_d = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^l (x_{id} - \\mu_d)^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**  По аналогии с вызовом one-hot encoder примените масштабирование вещественных признаков для обучающих и тестовых выборок X_train_real_zeros и X_test_real_zeros, используя класс \n",
    "\n",
    "        StandardScaler\n",
    "   \n",
    "   и методы \n",
    "\n",
    "        StandardScaler.fit_transform(...)\n",
    "        StandardScaler.transform(...)\n",
    "Сохраните ответ в переменные X_train_real_scaled и X_test_real_scaled соответственно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение признаковых пространств."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим такие же графики для преобразованных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_numeric_scaled = pd.DataFrame(X_train_real_scaled, columns=numeric_cols)\n",
    "list_cols = ['Number.of.Successful.Grant.1', 'SEO.Percentage.2', 'Year.of.Birth.1']\n",
    "scatter_matrix(data_numeric_scaled[list_cols], alpha=0.5, figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из графиков, мы не поменяли свойства признакового пространства: гистограммы распределений значений признаков, как и их scatter-plots, выглядят так же, как и до нормировки, но при этом все значения теперь находятся примерно в одном диапазоне, тем самым повышая интерпретабельность результатов, а также лучше сочетаясь с идеологией регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 3. Сравнение качества классификации до и после масштабирования вещественных признаков.\n",
    "1. Обучите ещё раз регрессию и гиперпараметры на новых признаках, объединив их с закодированными категориальными.\n",
    "2. Проверьте, был ли найден оптимум accuracy по гиперпараметрам во время кроссвалидации.\n",
    "3. Постройте ROC кривую на тесте.\n",
    "4. Получите значение ROC AUC на тестовой выборке, сравните с лучшим результатом, полученными ранее.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стратификация выборок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим пример с выборками, сэмплированными из двух гауссиан. Их мат. ожидания и матрицы ковариации заданы так, что истинная разделяющая поверхность должна проходить параллельно оси x. Поместим в обучающую выборку 20 объектов, сэмплированных из 1-й гауссианы, и 10 объектов из 2-й.  Посмотрим на качество классификаторов, получаемое на тестовых выборках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Насколько эти цифры реально отражают качество работы алгоритма, если учесть, что тестовая выборка так же несбалансирована, как обучающая?  Метрика классификатора на тесте имела бы гораздо больший смысл, если бы объекты были разделы в выборках поровну: по 20 из каждого класса на обучени и на тесте. Переформируем выборки и подсчитаем новые ошибки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAF5CAYAAAAVqLmkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f432ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.808333\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAF5CAYAAAAVqLmkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCAgtvTwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111b3df60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC for stratified samples:  0.825\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# Сэмплируем данные из первой гауссианы\n",
    "data_0 = np.random.multivariate_normal([0,0], [[0.5,0],[0,0.5]], size=40)\n",
    "# И из второй\n",
    "data_1 = np.random.multivariate_normal([0,1], [[0.5,0],[0,0.5]], size=40)\n",
    "# На обучение берём 20 объектов из первого класса и 10 из второго\n",
    "example_data_train = np.vstack([data_0[:20,:], data_1[:10,:]])\n",
    "example_labels_train = np.concatenate([np.zeros((20)), np.ones((10))])\n",
    "# На тест - 20 из первого и 30 из второго\n",
    "example_data_test = np.vstack([data_0[20:,:], data_1[10:,:]])\n",
    "example_labels_test = np.concatenate([np.zeros((20)), np.ones((30))])\n",
    "# Задаём координатную сетку, на которой будем вычислять область классификации\n",
    "xx, yy = np.meshgrid(np.arange(-3, 3, 0.02), np.arange(-3, 3, 0.02))\n",
    "\n",
    "# Первый раз классификацируем без стратификации\n",
    "optimizer = GridSearchCV(LogisticRegression(class_weight='balanced'), param_grid, cv=cv, n_jobs=-1)\n",
    "optimizer.fit(example_data_train, example_labels_train)\n",
    "Z = optimizer.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Pastel2)\n",
    "plt.scatter(data_0[:,0], data_0[:,1], color='red')\n",
    "plt.scatter(data_1[:,0], data_1[:,1], color='blue')\n",
    "auc_w_class_weights = roc_auc_score(example_labels_test, optimizer.predict(example_data_test))\n",
    "plt.title('With class weights (balanced)')\n",
    "plt.show()\n",
    "print('AUC: %f'%auc_w_class_weights)\n",
    "\n",
    "# Разделим данные по классам поровну между обучающей и тестовой выборками\n",
    "example_data_train = np.vstack([data_0[:20,:], data_1[:20,:]])\n",
    "example_labels_train = np.concatenate([np.zeros((20)), np.ones((20))])\n",
    "example_data_test = np.vstack([data_0[20:,:], data_1[20:,:]])\n",
    "example_labels_test = np.concatenate([np.zeros((20)), np.ones((20))])\n",
    "# Обучим классификатор на стратифицированной выборке\n",
    "optimizer = GridSearchCV(LogisticRegression(class_weight='balanced'), param_grid, cv=cv, n_jobs=-1)\n",
    "optimizer.fit(example_data_train, example_labels_train)\n",
    "Z = optimizer.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Pastel2)\n",
    "plt.scatter(data_0[:,0], data_0[:,1], color='red')\n",
    "plt.scatter(data_1[:,0], data_1[:,1], color='blue')\n",
    "auc_stratified = roc_auc_score(example_labels_test, optimizer.predict(example_data_test))\n",
    "plt.title('Stratified dataset')\n",
    "plt.show()\n",
    "print('AUC ROC for stratified samples: ', auc_stratified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, после данной процедуры ответ классификатора изменился незначительно, а вот качество увеличилось. При этом, в зависимости от того, как вы разбили изначально данные на обучение и тест, после сбалансированного разделения выборок итоговая метрика на тесте может как увеличиться, так и уменьшиться, но доверять ей можно значительно больше, т.к. она построена с учётом специфики работы классификатора. Данный подход является частным случаем т.н. метода стратификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 4. Стратификация выборки.\n",
    "\n",
    "1. По аналогии с тем, как это было сделано в начале семинара, разбейте выборки X_real_zeros и X_cat_oh на обучение и тест, передавая в функцию \n",
    "        train_test_split(...)\n",
    "   дополнительно параметр \n",
    "       stratify=y\n",
    "   Также обязательно передайте в функцию переменную random_state=0.\n",
    "2. Выполните масштабирование новых вещественных выборок, обучите классификатор и его гиперпараметры при помощи метода кросс-валидации, делая поправку на несбалансированные классы при помощи весов. Убедитесь в том, что нашли оптимум accuracy по гиперпараметрам.\n",
    "3. Оцените качество классификатора метрике AUC ROC на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Балансировка классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритмы классификации могут быть очень чувствительны к несбалансированным классам. Рассмотрим ещё раз пример с выборками из нормальных распределений. Обучим на них линейную регрессию, и построим на графиках объекты и области классификации.\n",
    "\n",
    "**Пример**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Обучаем регрессию без балансировки по классам\n",
    "optimizer = GridSearchCV(LogisticRegression(), param_grid, cv=cv, n_jobs=-1)\n",
    "optimizer.fit(example_data_train, example_labels_train)\n",
    "# Строим предсказания регрессии для сетки\n",
    "Z = optimizer.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Pastel2)\n",
    "plt.scatter(data_0[:,0], data_0[:,1], color='red')\n",
    "plt.scatter(data_1[:,0], data_1[:,1], color='blue')\n",
    "# Считаем AUC\n",
    "auc_wo_class_weights = roc_auc_score(example_labels_test, optimizer.predict(example_data_test))\n",
    "plt.title('Without class weights')\n",
    "plt.show()\n",
    "print('AUC: %f'%auc_wo_class_weights)\n",
    "\n",
    "# Для второй регрессии в LogisticRegression передаём параметр class_weight='balanced'\n",
    "optimizer = GridSearchCV(LogisticRegression(class_weight='balanced'), param_grid, cv=cv, n_jobs=-1)\n",
    "optimizer.fit(example_data_train, example_labels_train)\n",
    "Z = optimizer.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Pastel2)\n",
    "plt.scatter(data_0[:,0], data_0[:,1], color='red')\n",
    "plt.scatter(data_1[:,0], data_1[:,1], color='blue')\n",
    "auc_w_class_weights = roc_auc_score(example_labels_test, optimizer.predict(example_data_test))\n",
    "plt.title('With class weights (balanced)')\n",
    "plt.show()\n",
    "print('AUC: %f'%auc_w_class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, во втором случае классификатор находит разделяющую поверхность, которая ближе к истинной, т.е. меньше переобучается. Поэтому на сбалансированность классов в обучающей выборке всегда следует обращать внимание.\n",
    "\n",
    "**Задание.** Проверьте, сбалансированны ли классы в нашей обучающей выборке, т.е. посчитайте сколько 0 и 1 в обучающей выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие выводы можно сделать?\n",
    "\n",
    "Что делать в случае несбалансированных классов?\n",
    "* давать объектам миноритарного класса больший вес при обучении классификатора (рассмотрен в примере выше)\n",
    "* досэмплировать объекты миноритарного класса, пока число объектов в обоих классах не сравняется"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 5. Балансировка классов.\n",
    "1. Обучите логистическую регрессию и гиперпараметры с балансировкой классов, используя веса (параметр class_weight='balanced' регрессии) на отмасштабированных выборках, полученных в предыдущем задании. Убедитесь, что вы нашли максимум accuracy по гиперпараметрам.\n",
    "2. Постройте ROC кривую и получите метрику ROC AUC на тестовой выборке.\n",
    "3. Сбалансируйте выборку, досэмплировав в неё объекты из меньшего класса. Для получения индексов объектов, которые требуется добавить в обучающую выборку, используйте следующую комбинацию вызовов функций:\n",
    "        np.random.seed(0)\n",
    "        indices_to_add = np.random.randint(...)\n",
    "        X_train_to_add = X_train[y_train.as_matrix() == 1,:][indices_to_add,:]\n",
    "   После этого добавьте эти объекты в начало или конец обучающей выборки. Дополните соответствующим      образом вектор ответов.\n",
    "4. Получите метрику ROC AUC на тестовой выборке, сравните с предыдущим результатом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('AUC ROC for classifier without weighted classes', auc_wo_class_weights)\n",
    "print('AUC ROC for classifier with weighted classes: ', auc_w_class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вы разобрались с основными этапами предобработки данных для линейных классификаторов.\n",
    "Напомним основные этапы:\n",
    "- обработка пропущенных значений\n",
    "- обработка категориальных признаков\n",
    "- стратификация\n",
    "- балансировка классов\n",
    "- масштабирование\n",
    "\n",
    "Данные действия с данными рекомендуется проводить всякий раз, когда вы планируете использовать линейные методы. Рекомендация по выполнению многих из этих пунктов справедлива и для других методов машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Трансформация признаков.\n",
    "\n",
    "Теперь рассмотрим способы преобразования признаков. Существует достаточно много различных способов трансформации признаков, которые позволяют при помощи линейных методов получать более сложные разделяющие поверхности. Самым базовым является полиномиальное преобразование признаков. Его идея заключается в том, что помимо самих признаков вы дополнительно включаете набор все полиномы степени $p$, которые можно из них построить. Для случая $p=2$ преобразование выглядит следующим образом:\n",
    "\n",
    "$$ \\phi(x_i) = [x_{i,1}^2, ..., x_{i,D}^2, x_{i,1}x_{i,2}, ..., x_{i,D}, x_{i,D-1}, x_{i,1}, ..., x_{i,D}, 1] $$\n",
    "\n",
    "Рассмотрим принцип работы данных признаков на данных, сэмплированных из гауссиан:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Инициализируем класс, который выполняет преобразование\n",
    "transform = PolynomialFeatures(2)\n",
    "# Обучаем преобразование на обучающей выборке, применяем его к тестовой\n",
    "example_data_train_poly = transform.fit_transform(example_data_train)\n",
    "example_data_test_poly = transform.transform(example_data_test)\n",
    "# Обращаем внимание на параметр fit_intercept=False\n",
    "optimizer = GridSearchCV(LogisticRegression(class_weight='balanced', fit_intercept=False), param_grid, cv=cv, n_jobs=-1)\n",
    "optimizer.fit(example_data_train_poly, example_labels_train)\n",
    "Z = optimizer.predict(transform.transform(np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Pastel2)\n",
    "plt.scatter(data_0[:,0], data_0[:,1], color='red')\n",
    "plt.scatter(data_1[:,0], data_1[:,1], color='blue')\n",
    "plt.title('Balanced classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие выводы можно сделать, глядя на получившийся график?\n",
    "\n",
    "**Задание.** Выведите число признаков в новой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но при этом одновременно данный метод способствует более сильной способности модели к переобучению из-за быстрого роста числа признаком с увеличением степени $p$. Рассмотрим пример с $p=11$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform = PolynomialFeatures(11)\n",
    "example_data_train_poly = transform.fit_transform(example_data_train)\n",
    "example_data_test_poly = transform.transform(example_data_test)\n",
    "optimizer = GridSearchCV(LogisticRegression(class_weight='balanced', fit_intercept=False), param_grid, cv=cv, n_jobs=-1)\n",
    "optimizer.fit(example_data_train_poly, example_labels_train)\n",
    "Z = optimizer.predict(transform.transform(np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Pastel2)\n",
    "plt.scatter(data_0[:,0], data_0[:,1], color='red')\n",
    "plt.scatter(data_1[:,0], data_1[:,1], color='blue')\n",
    "plt.title('Corrected class weights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что можно сказать по поводу этой модели?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество признаков в данной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 6. Трансформация вещественных признаков.\n",
    "\n",
    "1. Реализуйте по аналогии с примером преобразование вещественных признаков модели при помощи полиномиальных признаков степени 2\n",
    "2. Постройте логистическую регрессию на новых данных, одновременно подобрав оптимальные гиперпараметры. Обращаем внимание, что в преобразованных признаках уже присутствует столбец, все значения которого равны 1, поэтому обучать дополнительно значение $b$ не нужно, его функцию выполняет один из весов $w$. В связи с этим во избежание линейной зависимости в датасете, в вызов класса логистической регрессии требуется передавать параметр fit_intercept=False. Для обучения используйте стратифицированные выборки с балансировкой классов при помощи весов, преобразованные признаки требуется заново отмасштабировать.\n",
    "3. Получите AUC ROC на тесте и сравните данный результат с использованием обычных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регрессия Lasso.\n",
    "К логистической регрессии также можно применить L1-регуляризацию (Lasso), вместо регуляризации L2, которая будет приводить к отбору признаков. Вам предлагается применить L1-регуляцию к исходным признакам и проинтерпретировать полученные результаты (применение отбора признаков к полиномиальным так же можно успешно применять, но в нём уже будет отсутствовать компонента интерпретации, т.к. смысловое значение оригинальных признаков известно, а полиномиальных - уже может быть достаточно нетривиально). Для вызова логистической регрессии с L1-регуляризацией достаточно передать параметр penalty='l1' в инициализацию класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 7. Отбор признаков при помощи регрессии Lasso.\n",
    "1. Обучите регрессию Lasso на стратифицированных отмасштабированных выборках, используя балансировку классов при помощи весов.\n",
    "2. Получите ROC AUC регрессии, сравните его с предыдущими результатами.\n",
    "3. Найдите номера вещественных признаков, которые имеют нулевые веса в итоговой модели. Какие значения они имеют?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# место для вашего кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
